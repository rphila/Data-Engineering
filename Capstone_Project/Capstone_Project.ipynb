{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laotian Immigration Patterns in 2016\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project will investigate trends of Laotian immigration to the US in 2016. Raw datasets on immigration, city temperature and city demographics will be collected and uploaded into S3. Then python and Spark will be used to transform the raw data from S3 into a database schema suitable for analysis in a Redshift data warehouse. This ETL pipeline will be orchestrated using Airflow. \n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spack session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "We are interested in investigating any patterns in temperature and city demographics that is observed for Laotian immigrants. To do this, \n",
    "datasets on immigration, city temperature, and city demographics will first be collected. \n",
    "\n",
    "Next, a data model will be created that is optimized for joins against city data. This data model will consist of dimension tables for city dempographics and city temperatures. Fact tables will be created from the immigration dataset. \n",
    "\n",
    "This star schema data model will then allow for queries that analyze what type of temperature and demographics in a destination city are common for Laotian immigrants. Since the immigration dataset is large (over 1 million records), Spark will be used to allow for massively parallel data processing.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The I94 Immigration Data is in SAS7BDAT format and comes from the US National Tourism and Trade Office: https://travel.trade.gov/research/reports/i94/historical/2016.html\n",
    "The data dictionary is in the _I94_SAS_Labels_Descriptions.SAS_ file. \n",
    "\n",
    "##### Notable fields include: \n",
    "- i94yr - 4 digit year\n",
    "- i94mon - Numeric month\n",
    "- i94cit - origin\n",
    "- i94port - arrival destination (city, state for US)\n",
    "- arrdate - arrival Date in the USA\n",
    "- i94mode - mode of transportation\n",
    "- depdate - the Departure Date from the USA\n",
    "- i94bir - Age of Respondent in Years\n",
    "- i94visa - Visa codes (1=Business, 2=Pleasure, 3=Student)\n",
    "- dtadfile - Character Date Field\n",
    "- occup - Occupation that will be performed in U.S.\n",
    "- biryear - 4 digit year of birth\n",
    "- gender - Non-immigrant sex\n",
    "\n",
    "\n",
    "The World Temperature Data is in csv format and comes from Kaggle: \n",
    "https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "\n",
    "The U.S. City Demographic Data is in csv format and comes from OpenSoft: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "The Airport Code Table is a simple csv table of airport codes and corresponding cities. It comes from here: https://datahub.io/core/airport-codes#data (_NOTE: this dataset may not be needed in our data model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "# immigration data sample\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# city temperature data \n",
    "fname2 = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname2)\n",
    "\n",
    "# city demographics\n",
    "df_citydemo = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "\n",
    "# airport data\n",
    "df_airport = pd.read_csv('airport-codes_csv.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096313, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    37.0      2.0    1.0       NaN      NaN   NaN       T     NaN   \n",
       "1      NaN    25.0      3.0    1.0  20130811      SEO   NaN       G     NaN   \n",
       "2  20691.0    55.0      2.0    1.0  20160401      NaN   NaN       T       O   \n",
       "3  20567.0    28.0      2.0    1.0  20160401      NaN   NaN       O       O   \n",
       "4  20567.0     4.0      2.0    1.0  20160401      NaN   NaN       O       O   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0       U     NaN   1979.0  10282016    NaN    NaN     NaN  1.897628e+09   \n",
       "1       Y     NaN   1991.0       D/S      M    NaN     NaN  3.736796e+09   \n",
       "2     NaN       M   1961.0  09302016      M    NaN      OS  6.666432e+08   \n",
       "3     NaN       M   1988.0  09302016    NaN    NaN      AA  9.246846e+10   \n",
       "4     NaN       M   2012.0  09302016    NaN    NaN      AA  9.246846e+10   \n",
       "\n",
       "   fltno visatype  \n",
       "0    NaN       B2  \n",
       "1  00296       F1  \n",
       "2     93       B2  \n",
       "3  00199       B2  \n",
       "4  00199       B2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#immigration data\n",
    "\n",
    "pd.set_option('display.max_columns', 28)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3574989, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20612.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>10032016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.493846e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20612.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>10032016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.746006e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20609.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.679298e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20611.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.140963e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.934535e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    4.0  2016.0     6.0   135.0   135.0     XXX  20612.0      NaN     NaN   \n",
       "1    5.0  2016.0     6.0   135.0   135.0     XXX  20612.0      NaN     NaN   \n",
       "2    6.0  2016.0     6.0   213.0   213.0     XXX  20609.0      NaN     NaN   \n",
       "3    7.0  2016.0     6.0   213.0   213.0     XXX  20611.0      NaN     NaN   \n",
       "4   16.0  2016.0     6.0   245.0   245.0     XXX  20632.0      NaN     NaN   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto  gender  insnum  \\\n",
       "0      NaN   ...           U      NaN   1957.0  10032016     NaN     NaN   \n",
       "1      NaN   ...           U      NaN   1966.0  10032016     NaN     NaN   \n",
       "2      NaN   ...           U      NaN   1989.0       D/S     NaN     NaN   \n",
       "3      NaN   ...           U      NaN   1993.0       D/S     NaN     NaN   \n",
       "4      NaN   ...           U      NaN   1992.0       D/S     NaN     NaN   \n",
       "\n",
       "   airline        admnum  fltno visatype  \n",
       "0      NaN  1.493846e+10    NaN       WT  \n",
       "1      NaN  1.746006e+10    NaN       WT  \n",
       "2      NaN  1.679298e+09    NaN       F1  \n",
       "3      NaN  1.140963e+09    NaN       F1  \n",
       "4      NaN  1.934535e+09    NaN       F1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# immigration data sample\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat'\n",
    "df2 = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8599212, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>-2.691</td>\n",
       "      <td>0.272</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2.429</td>\n",
       "      <td>0.427</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>7.123</td>\n",
       "      <td>0.234</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>10.657</td>\n",
       "      <td>0.314</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>14.989</td>\n",
       "      <td>0.272</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "3195  2010-02-01              -2.691                          0.272  Århus   \n",
       "3196  2010-03-01               2.429                          0.427  Århus   \n",
       "3197  2010-04-01               7.123                          0.234  Århus   \n",
       "3198  2010-05-01              10.657                          0.314  Århus   \n",
       "3199  2010-06-01              14.989                          0.272  Århus   \n",
       "\n",
       "      Country Latitude Longitude  \n",
       "3195  Denmark   57.05N    10.33E  \n",
       "3196  Denmark   57.05N    10.33E  \n",
       "3197  Denmark   57.05N    10.33E  \n",
       "3198  Denmark   57.05N    10.33E  \n",
       "3199  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temperature data\n",
    "\n",
    "print(df_temp.shape)\n",
    "df_temp.head()\n",
    "df_temp[(df_temp['dt'] > '2010-01-01') & (df_temp['dt'] < '2017-01-01')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_temp['Country'].unique()\n",
    "#sorted(countries, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_citydemo.shape)\n",
    "df_citydemo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>693826.0</td>\n",
       "      <td>701081.0</td>\n",
       "      <td>1394907</td>\n",
       "      <td>92489.0</td>\n",
       "      <td>373842.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>949388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>693826.0</td>\n",
       "      <td>701081.0</td>\n",
       "      <td>1394907</td>\n",
       "      <td>92489.0</td>\n",
       "      <td>373842.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>267222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>693826.0</td>\n",
       "      <td>701081.0</td>\n",
       "      <td>1394907</td>\n",
       "      <td>92489.0</td>\n",
       "      <td>373842.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>425414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>693826.0</td>\n",
       "      <td>701081.0</td>\n",
       "      <td>1394907</td>\n",
       "      <td>92489.0</td>\n",
       "      <td>373842.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>111650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>693826.0</td>\n",
       "      <td>701081.0</td>\n",
       "      <td>1394907</td>\n",
       "      <td>92489.0</td>\n",
       "      <td>373842.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>16496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City       State  Median Age  Male Population  Female Population  \\\n",
       "236   San Diego  California        34.5         693826.0           701081.0   \n",
       "524   San Diego  California        34.5         693826.0           701081.0   \n",
       "1392  San Diego  California        34.5         693826.0           701081.0   \n",
       "1754  San Diego  California        34.5         693826.0           701081.0   \n",
       "2769  San Diego  California        34.5         693826.0           701081.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "236            1394907             92489.0      373842.0   \n",
       "524            1394907             92489.0      373842.0   \n",
       "1392           1394907             92489.0      373842.0   \n",
       "1754           1394907             92489.0      373842.0   \n",
       "2769           1394907             92489.0      373842.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "236                     2.73         CA                              White   \n",
       "524                     2.73         CA                              Asian   \n",
       "1392                    2.73         CA                 Hispanic or Latino   \n",
       "1754                    2.73         CA          Black or African-American   \n",
       "2769                    2.73         CA  American Indian and Alaska Native   \n",
       "\n",
       "       Count  \n",
       "236   949388  \n",
       "524   267222  \n",
       "1392  425414  \n",
       "1754  111650  \n",
       "2769   16496  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citydemo[(df_citydemo['State Code']=='CA') & (df_citydemo['City']=='San Diego')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55075, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_airport.shape)\n",
    "df_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>01CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Los Angeles County Sheriff's Department Heliport</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>01CN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01CN</td>\n",
       "      <td>-118.15399932861328, 34.03779983520508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0CA0</td>\n",
       "      <td>closed</td>\n",
       "      <td>Drew Medical Center Heliport</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-118.241997, 33.923302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0CL7</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Good Samaritan Hospital Heliport</td>\n",
       "      <td>473.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0CL7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0CL7</td>\n",
       "      <td>-118.264967, 34.054901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>14L</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Devonshire Area Heliport</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>14L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14L</td>\n",
       "      <td>-118.53099822998047, 34.256900787353516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>22CN</td>\n",
       "      <td>heliport</td>\n",
       "      <td>ABC-TV Heliport</td>\n",
       "      <td>422.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>22CN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22CN</td>\n",
       "      <td>-118.28299713134766, 34.10329818725586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident      type                                              name  \\\n",
       "71    01CN  heliport  Los Angeles County Sheriff's Department Heliport   \n",
       "639   0CA0    closed                      Drew Medical Center Heliport   \n",
       "666   0CL7  heliport                  Good Samaritan Hospital Heliport   \n",
       "1459   14L  heliport                          Devonshire Area Heliport   \n",
       "2500  22CN  heliport                                   ABC-TV Heliport   \n",
       "\n",
       "      elevation_ft continent iso_country iso_region municipality gps_code  \\\n",
       "71           300.0       NaN          US      US-CA  Los Angeles     01CN   \n",
       "639          180.0       NaN          US      US-CA  Los Angeles      NaN   \n",
       "666          473.0       NaN          US      US-CA  Los Angeles     0CL7   \n",
       "1459        1012.0       NaN          US      US-CA  Los Angeles      14L   \n",
       "2500         422.0       NaN          US      US-CA  Los Angeles     22CN   \n",
       "\n",
       "     iata_code local_code                              coordinates  \n",
       "71         NaN       01CN   -118.15399932861328, 34.03779983520508  \n",
       "639        NaN        NaN                   -118.241997, 33.923302  \n",
       "666        NaN       0CL7                   -118.264967, 34.054901  \n",
       "1459       NaN        14L  -118.53099822998047, 34.256900787353516  \n",
       "2500       NaN       22CN   -118.28299713134766, 34.10329818725586  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_airport = pd.read_csv('airport-codes_csv.csv')\n",
    "df_airport[(df_airport['iso_region']=='US-CA') & (df_airport['municipality'] =='Los Angeles')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08606481552124023\n",
      "56.82417678833008\n",
      "0.14061450958251953\n"
     ]
    }
   ],
   "source": [
    "# write to parquet\n",
    "\n",
    "t1 = time.time()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "df_spark.write.mode(\"overwrite\").parquet(\"sas_data2\")\n",
    "t3 = time.time()\n",
    "print(t3-t2)\n",
    "df_spark=spark.read.parquet(\"sas_data2\")\n",
    "t4 = time.time()\n",
    "print(t4-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160430</td>\n",
       "      <td>SYD</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa  \\\n",
       "0      CA  20582.0    40.0      1.0    1.0  20160430      SYD  None       G   \n",
       "1      NV  20591.0    32.0      1.0    1.0  20160430      SYD  None       G   \n",
       "2      WA  20582.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "3      WA  20588.0    29.0      1.0    1.0  20160430      SYD  None       G   \n",
       "4      WA  20588.0    28.0      1.0    1.0  20160430      SYD  None       G   \n",
       "\n",
       "  entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0       O    None       M   1976.0  10292016      F   None      QF   \n",
       "1       O    None       M   1984.0  10292016      F   None      VA   \n",
       "2       O    None       M   1987.0  10292016      M   None      DL   \n",
       "3       O    None       M   1987.0  10292016      F   None      DL   \n",
       "4       O    None       M   1988.0  10292016      M   None      DL   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  9.495387e+10  00011       B1  \n",
       "1  9.495562e+10  00007       B1  \n",
       "2  9.495641e+10  00040       B1  \n",
       "3  9.495645e+10  00040       B1  \n",
       "4  9.495639e+10  00040       B1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n",
    "From the data exploration above, many data cleaning steps are needed to prepare the raw datasets for the data model.\n",
    "\n",
    "First, the temperature data contains many records with _NaN_ Average temperature, which should be filtered out. Also, since we are only interested in immigration to the US around 2016, the temperature data can be filtered further to contain only countries in 'United States' and dates around 2016 (2010-2017). \n",
    "\n",
    "For the immigration data, since we are only interested in those from origin country Laos, we can ignore all *i94cit* fields that are not equal to the LAOS code of 203.0. \n",
    "\n",
    "Next, the city demographics data table will need to be normalized by removing the *Race* and *Count* columns, along with the *City*, into another table. This will allow for a unique record for each city in the main demographics table.\n",
    "\n",
    "When querying, *i94port* from immigration dataset can then be joined to *City* from both the Temperature and Demographics dataset.\n",
    "\n",
    "#### Cleaning Steps\n",
    "\n",
    "In order to clean the dataset, these steps will be performed:\n",
    "\n",
    "- Temperature data: filter for records where *Country* = 'United States', *dt* between 2010-2017, and *AverageTemperature* is not _NaN_; duplicates will be dropped\n",
    "\n",
    "- City Demographic data: the table will need to be normalized by removing the *Race* and *Count* into a separate table; duplicates will be dropped from both tables created\n",
    "\n",
    "- I94 Immigration data: filter out only records where *i94cit* is _203.0_ (LAOS); also june dataset has 6 extra columns, so june dataset will be skipped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and filter the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n",
      "596\n",
      "2834\n"
     ]
    }
   ],
   "source": [
    "# clean and normalize city demographics (Race and Count are columns 10-11)\n",
    "\n",
    "df_citydemo_filt = df_citydemo.iloc[:,:10].drop_duplicates()\n",
    "df_citydemo_race = df_citydemo.iloc[:,10:].drop_duplicates()\n",
    "\n",
    "print(len(df_citydemo))\n",
    "print(len(df_citydemo_filt))\n",
    "print(len(df_citydemo_race))\n",
    "\n",
    "df_citydemo_filt.to_csv(\"city_demo.csv\", index=False)\n",
    "df_citydemo_race.to_csv(\"city_race.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599212\n",
      "11307\n",
      "1.9743242263793945\n"
     ]
    }
   ],
   "source": [
    "# clean city temperature data \n",
    "\n",
    "t1 = time.time()\n",
    "df_temp_filt = df_temp[(df_temp['Country']=='United States') & (pd.notna(df_temp['AverageTemperature'])) \n",
    "                       & (df_temp['dt'] > '2010-01-01') & (df_temp['dt'] < '2017-01-01')].drop_duplicates()\n",
    "\n",
    "print(len(df_temp))\n",
    "print(len(df_temp_filt))\n",
    "df_temp_filt.to_csv(\"temperature_US.csv\", index=False)\n",
    "\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat\n",
      "4.167316436767578\n",
      "jan (77, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat\n",
      "0.20766663551330566\n",
      "feb (50, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat\n",
      "0.17574572563171387\n",
      "mar (55, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\n",
      "0.2185685634613037\n",
      "apr (113, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat\n",
      "0.17664456367492676\n",
      "may (93, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat\n",
      "0.17773652076721191\n",
      "jul (250, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat\n",
      "0.20240092277526855\n",
      "aug (218, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat\n",
      "0.16498851776123047\n",
      "sep (135, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat\n",
      "0.14185786247253418\n",
      "oct (200, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat\n",
      "0.15395283699035645\n",
      "nov (119, 28)\n",
      "../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat\n",
      "0.16918325424194336\n",
      "dec (125, 28)\n"
     ]
    }
   ],
   "source": [
    "# clean immigration data\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "def filter_i94_data(file, m):\n",
    "    '''\n",
    "    Input: path to I94 immigration data\n",
    "    Output: Spark dataframe of I94 immigration data filtered for LAOS immigrants\n",
    "    '''\n",
    "    print(file)\n",
    "    t1 = time.time() \n",
    "    \n",
    "    # Read data into Spark\n",
    "    df_i94 = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "\n",
    "    # Filter for entires where i94cit is 203 (LAOS)\n",
    "    df_i94_filt = df_i94.filter(df_i94.i94cit.isin(203))\n",
    "\n",
    "  #  out_dir ='laos_i94'\n",
    " #   if m == 'jan':\n",
    " #       if os.path.exists(out_dir):\n",
    " #           shutil.rmtree(out_dir)\n",
    " #       os.makedirs(out_dir)      \n",
    "\n",
    "  #  df_i94_filt.write.mode(\"append\").parquet(out_dir)\n",
    "  #  df_i94_filt=spark.read.parquet(out_dir)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    return df_i94_filt\n",
    "\n",
    "\n",
    "# Run function\n",
    "df = pd.DataFrame()\n",
    "# skip june dataset which has extra columns\n",
    "month_list = ['jan', 'feb', 'mar', 'apr', 'may', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "for m in month_list:  \n",
    "    filepath = '../../data/18-83510-I94-Data-2016/i94_'+m+'16_sub.sas7bdat' \n",
    "    df_i94_filt = filter_i94_data(filepath, m)\n",
    "    print(m, (df_i94_filt.count(), len(df_i94_filt.columns)))\n",
    "        \n",
    "    if m == 'jan':\n",
    "        df = df_i94_filt.toPandas()\n",
    "    else:\n",
    "        df.append(df_i94_filt.toPandas(), ignore_index=True)\n",
    "\n",
    "    #df_i94_filt.show(3)\n",
    "\n",
    "df.to_csv(\"i94_laos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "![database schema](\"i94_city_demo.png\")\n",
    "\n",
    "The data model will consist of a dimension table for the city temperature, city demographics and race demographics. Then there will be a fact table for the i94 immigration data.\n",
    "\n",
    "This star schema data model will allow joining immigration data to features of a city that they immigrated to, such as temerature and various demographics (race/gender/population). More specifically, this data model allows queries that involve joining *i94port* from immigration dataset to *City* from both the Temperature and City Demographics datasets.\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "The data pipeline to process the raw data into the data model for analysis are as follows:\n",
    "\n",
    "##### Pre-Processing\n",
    "1. Clean and filter the dataset:\n",
    "   - Use python to clean and filter the temperature data to only US cities around 2016\n",
    "   - ~~Use python to normalize the city demographics dataset into 2 tables: 1 normalized for unique cities, the other with Race demographics~~ (Transformaton will happen during ETL)\n",
    "   - Use spark to filter the i94 immigration dataset to only immigrants from LAOS and save into parquet files\n",
    "2. Upload the cleaned dataset into S3\n",
    "\n",
    "##### ETL\n",
    "1. Use SQL to create the redshift staging tables\n",
    "2. Use SQL to create the redshift fact and dimension tables for the data model\n",
    "3. Use the cleaned and filtered datasets in S3 as the source data to insert into the redshift staging tables\n",
    "4. Transform and load the data from tge staging tables into the final redshift star schema tables \n",
    "5. Verify tables are not empty and record count in table and csv matches for those that should match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the raw dataset\n",
    "!python data_cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to S3\n",
    "!python upload_to_S3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"etl.py\", line 47, in <module>\n",
      "    main()\n",
      "  File \"etl.py\", line 41, in main\n",
      "    insert_tables(cur, conn)\n",
      "  File \"etl.py\", line 28, in insert_tables\n",
      "    cur.execute(query)\n",
      "psycopg2.ProgrammingError: column \"dt\" does not exist in s, c, unnamed_join\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run ETL to transform data from S3 into data model in redshift\n",
    "# Requires going through AWS_Setup.ipynb to setup Redshift cluster first\n",
    "!python etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "citydemo\n",
    "- citydemo_id: autoincremented primary key\n",
    "- City: distinct city from us-cities-demographics.csv\n",
    "- State: state of city from us-cities-demographics.csv\n",
    "- MedianAge: median age of city from us-cities-demographics.csv\n",
    "- MalePopulation: male population of city from us-cities-demographics.csv\n",
    "- FemalePopulation: femalepopulation of city from us-cities-demographics.csv\n",
    "- TotalPopulation: total population of city from us-cities-demographics.csv\n",
    "- NumberVeterans: # of vertains in city from us-cities-demographics.csv\n",
    "- ForeignBorn: # foreign born in city from us-cities-demographics.csv\n",
    "- AverageHouseholdSize: average household size in city from us-cities-demographics.csv\n",
    "- StateCode: state code of city from us-cities-demographics.csv\n",
    "\n",
    "cityrace\n",
    "- cityrace_id: autoincremented primary key\n",
    "- citydemo_id: foreign key to citydemo on City\n",
    "- Race: race being counted\n",
    "- Count: count of race in city\n",
    "\n",
    "temperature\n",
    "- temperature_id: autoincremented primary key\n",
    "- dt: date of temperature from GlobalLandTemperaturesByCity.csv\n",
    "- AverageTemperature: average temperature from GlobalLandTemperaturesByCity.csv\n",
    "- AverageTemperatureUncertainty: average temperature uncertainty from GlobalLandTemperaturesByCity.csv\n",
    "- City: city having temperature from GlobalLandTemperaturesByCity.csv\n",
    "- citydemo_id: foreign key to citydemo on City\n",
    "- Country: country of city from GlobalLandTemperaturesByCity.csv\n",
    "- Latitude: latitude from GlobalLandTemperaturesByCity.csv\n",
    "- Longitude: longitude from GlobalLandTemperaturesByCity.csv\n",
    "\n",
    "i94\n",
    "- i94_id: autoincremented primary key\n",
    "- i94yr - 4 digit year from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- i94mon - Numeric month from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- i94cit - origin location from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- i94port - arrival destination (city, state for US)  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- citydemo_id: foreign key to citydemo on City\n",
    "- arrdate - arrival Date in the USA  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- i94mode - mode of transportation  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- depdate - the Departure Date from the USA  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- i94bir - Age of Respondent in Years  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- i94visa - Visa codes (1=Business, 2=Pleasure, 3=Student)  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- dtadfile - Character Date Field  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- occup - Occupation that will be performed in U.S.  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- biryear - 4 digit year of birth  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n",
    "- gender - Non-immigrant sex  from 18-83510-I94-Data-2016/i94_XXX16_sub.sas7bdat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
